# /api/routers/avatar_api.py (FINAL FIX - Corrected Payload Keys)

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState, WebSocketDisconnect as StarletteWebSocketDisconnect
import json
import random
import logging
import asyncio
from typing import Optional, List, Dict, Any 
from core.ai_models.rag_orchestrator import RAGOrchestrator
from core.ai_models.speech_handler import speech_handler_instance
from core.config import settings
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends
from ..dependencies import get_rag_orchestrator

def sanitize_for_json(obj):
    if isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_for_json(elem) for elem in obj]
    elif isinstance(obj, (str, int, float, bool)) or obj is None:
        return obj
    else:
        return str(obj)

def construct_full_image_url(image_path: str | None) -> str | None:
    if not image_path: return None
    if image_path.startswith(('http://', 'https://')):
        return image_path
    if image_path.startswith('/'):
        return f"http://{settings.API_HOST}:{settings.API_PORT}{image_path}"
    return image_path

router = APIRouter(tags=["Avatar"])

def is_websocket_active(ws: WebSocket) -> bool:
    return ws.application_state == WebSocketState.CONNECTED

async def _handle_idle_prompt(websocket: WebSocket):
    if not is_websocket_active(websocket): return
    idle_prompts = ["‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞?", "‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏™‡∏ß‡∏¢‡πÜ ‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡∏î‡∏π‡∏™‡∏¥‡∏Ñ‡∏∞"]
    text_to_speak = random.choice(idle_prompts)
    payload = {
        "answer": text_to_speak, # [FIX] Use 'answer' for consistency
        "emotion": "talking",
        "isIdlePrompt": True 
    }
    try:
        await websocket.send_text(json.dumps(payload))
        if is_websocket_active(websocket):
            async for audio_chunk in speech_handler_instance.synthesize_speech_stream(text_to_speak):
                if is_websocket_active(websocket):
                    await websocket.send_bytes(audio_chunk)
    except Exception as e:
        logging.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• idle prompt: {e}", exc_info=True)

async def process_orchestrator_result(result: Dict[str, Any]) -> Dict[str, Any]:
    """
    Translates the V5 orchestrator response into a WebSocket payload with consistent keys.
    """
    # [FIX] Start with the correct 'answer' key
    payload = {
        "answer": result.get("answer", "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î"),
        "action": result.get("action"),
        "action_payload": result.get("action_payload"),
    }

    image_url = result.get("image_url")
    image_gallery = result.get("image_gallery", [])
    sources = result.get("sources", [])
    
    if result.get("action") and "MUSIC" in result["action"]:
        payload["emotion"] = "listening"
    elif image_url or image_gallery or sources:
        payload["emotion"] = "happy"
    else:
        payload["emotion"] = "talking"

    # [FIX] Use consistent 'image_url' key with underscore
    payload["image_url"] = construct_full_image_url(image_url)
    payload["image_gallery"] = [construct_full_image_url(url) for url in image_gallery if url]
    
    # üîç DEBUG: Log image URL construction
    logging.info(f"üñºÔ∏è [Avatar] Image Debug - Raw: image_url={image_url}, gallery={image_gallery}")
    logging.info(f"üñºÔ∏è [Avatar] Image Debug - Constructed: image_url={payload['image_url']}, gallery={payload['image_gallery']}")
    
    processed_sources = []
    for source in sources:
        processed_source = source.copy()
        raw_urls = processed_source.get("image_urls", [])
        processed_source["image_urls"] = [construct_full_image_url(url) for url in raw_urls if url]
        processed_sources.append(processed_source)
    payload["sources"] = processed_sources

    logging.debug(f"‡∏™‡∏£‡πâ‡∏≤‡∏á WebSocket Payload: {payload}")
    return payload

# --- The rest of the file is correct and does not need changes ---
# ... (_handle_audio_input, _handle_text_input, handle_avatar_chat) ...

async def _handle_audio_input(websocket: WebSocket, audio_bytes: bytes, orchestrator: RAGOrchestrator, ai_mode: str = 'fast'):
    if not is_websocket_active(websocket): return
    try:
        await websocket.send_text(json.dumps({"emotion": "thinking"}))
        transcribed_text = await speech_handler_instance.transcribe_audio_bytes(audio_bytes)
        if not transcribed_text:
            if is_websocket_active(websocket):
                await websocket.send_text(json.dumps({"emotion": "confused", "answer": "‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡∏û‡∏π‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞", "isEmpty": True}))
            return
        logging.info(f"üëÇ [Avatar WebSocket] ‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô (‡∏î‡∏¥‡∏ö): '{transcribed_text}' | ‡πÇ‡∏´‡∏°‡∏î: {ai_mode}")
        result = await orchestrator.answer_query(transcribed_text, mode='voice', ai_mode=ai_mode)
        payload = await process_orchestrator_result(result)
        
        # [FIX] Skip TTS for MUSIC actions - no need to speak when playing music
        action = payload.get("action", "")
        is_music_action = action and "MUSIC" in action
        
        text_to_speak = payload.get("answer")
        audio_task = None
        
        if text_to_speak and not is_music_action:
             # audio_task deprecated, now streaming directly
             pass
        elif is_music_action:
            logging.info("üéµ [Avatar] ‡∏Ç‡πâ‡∏≤‡∏° TTS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏î‡∏ô‡∏ï‡∏£‡∏µ")
            
        sanitized_payload = sanitize_for_json(payload)
        await websocket.send_text(json.dumps(sanitized_payload))
        
        if text_to_speak and not is_music_action:
            if is_websocket_active(websocket):
                 async for audio_chunk in speech_handler_instance.synthesize_speech_stream(text_to_speak):
                     if is_websocket_active(websocket):
                         await websocket.send_bytes(audio_chunk)
    except (WebSocketDisconnect, StarletteWebSocketDisconnect, ConnectionResetError, BrokenPipeError):
        # Client disconnected during response - this is normal
        logging.info("üì¥ [WebSocket] Audio stream interrupted by client (Normal)")
    except Exception as e:
        logging.error(f"‚ùå [WebSocket] Error handling audio input: {e}", exc_info=True)
        if is_websocket_active(websocket):
            try:
                await websocket.send_text(json.dumps({"emotion": "confused", "answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"}))
            except:
                pass

async def _handle_text_input(websocket: WebSocket, query_text: str, orchestrator: RAGOrchestrator, ai_mode: str = 'fast'):
    if not is_websocket_active(websocket): return
    try:
        await websocket.send_text(json.dumps({"emotion": "thinking"}))
        logging.info(f"‚å®Ô∏è [Avatar WebSocket] ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°): '{query_text}' | ‡πÇ‡∏´‡∏°‡∏î: {ai_mode}")
        result = await orchestrator.answer_query(query_text, mode='voice', ai_mode=ai_mode)
        payload = await process_orchestrator_result(result)
        
        # [FIX] Skip TTS for MUSIC actions - no need to speak when playing music
        action = payload.get("action", "")
        is_music_action = action and "MUSIC" in action
        
        text_to_speak = payload.get("answer")
        
        if is_music_action:
            logging.info("üéµ [Avatar] ‡∏Ç‡πâ‡∏≤‡∏° TTS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏î‡∏ô‡∏ï‡∏£‡∏µ")
            
        sanitized_payload = sanitize_for_json(payload)
        await websocket.send_text(json.dumps(sanitized_payload))
        
        if text_to_speak and not is_music_action:
            if is_websocket_active(websocket):
                try:
                    async for audio_chunk in speech_handler_instance.synthesize_speech_stream(text_to_speak):
                        if is_websocket_active(websocket):
                            await websocket.send_bytes(audio_chunk)
                except (WebSocketDisconnect, StarletteWebSocketDisconnect, ConnectionResetError, BrokenPipeError):
                    logging.info("üì¥ [WebSocket] Audio stream interrupted by client (Normal)")
                except Exception as e:
                    logging.error(f"‚ùå [Avatar WS] Error streaming audio: {e}")
                finally:
                    # [CRITICAL] Always send END signal
                    if is_websocket_active(websocket):
                        await websocket.send_text(json.dumps({"action": "AUDIO_STREAM_END"}))
                                        
    except (WebSocketDisconnect, StarletteWebSocketDisconnect, ConnectionResetError, BrokenPipeError):
        logging.info("üì¥ [WebSocket] Text response interrupted by client (Normal)")
    except Exception as e:
         logging.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {e}", exc_info=True)
         if is_websocket_active(websocket):
            try:
                await websocket.send_text(json.dumps({"emotion": "confused", "answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"}))
            except:
                pass

@router.websocket("/ws")
async def handle_avatar_chat(websocket: WebSocket, orchestrator: RAGOrchestrator = Depends(get_rag_orchestrator)):
    await websocket.accept()
    
    # üÜï State tracking per connection
    current_ai_mode = 'fast' 
    
    try:
        while True:
            try:
                message = await websocket.receive()
                
                if message["type"] == "websocket.receive":
                    if text_data := message.get("text"):
                        try:
                            data = json.loads(text_data)
                            
                            # üîÑ Update state if provided
                            if "ai_mode" in data:
                                current_ai_mode = data["ai_mode"]
                            
                            if query := data.get("query"):
                                await _handle_text_input(websocket, query, orchestrator, current_ai_mode)
                            elif data.get("action") == "idle_prompt":
                                await _handle_idle_prompt(websocket)
                            elif data.get("action") == "SET_MODE":
                                logging.info(f"üîÑ [Avatar WS] ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô: {current_ai_mode}")
                                
                        except Exception as e:
                             logging.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {e}", exc_info=True)
                             if is_websocket_active(websocket):
                                 try:
                                     await websocket.send_text(json.dumps({"emotion": "confused", "answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"}))
                                 except:
                                     pass

                    elif bytes_data := message.get("bytes"):
                        # üé§ Ensure audio uses the current mode
                        await _handle_audio_input(websocket, bytes_data, orchestrator, ai_mode=current_ai_mode) 
                
                elif message["type"] == "websocket.disconnect":
                    break

            except (WebSocketDisconnect, StarletteWebSocketDisconnect):
                logging.info("üì¥ [WebSocket] Disconnected.")
                break
            except Exception as e:
                logging.error(f"‚ùå [WebSocket Loop Error]: {e}", exc_info=True)
                break

    except Exception as e:
        logging.error(f"‚ùå [Avatar WebSocket] Fatal Error: {e}", exc_info=True)
    finally:
        logging.info("üõë [Avatar WebSocket] ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")