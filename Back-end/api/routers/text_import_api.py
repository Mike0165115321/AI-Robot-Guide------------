"""
Text Import API - AI-Powered Text Extraction
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏≤‡∏Å raw text ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Gemini AI
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

import google.generativeai as genai
from core.config import settings
from core.ai_models.key_manager import gemini_key_manager

router = APIRouter(prefix="/api/ai", tags=["AI :: Text Import"])

# Constants
MAX_RETRIES = 3
EXTRACTION_MODEL = "gemini-2.0-flash"


# =============================================================================
# Pydantic Models
# =============================================================================

class TextExtractRequest(BaseModel):
    """Request body for text extraction"""
    raw_text: str = Field(..., min_length=10, description="Raw text to extract locations from")


class ExtractedLocation(BaseModel):
    """Single extracted location"""
    title: str
    category: str
    description: str
    keywords: List[str] = []
    location_guess: Optional[str] = None


class TextExtractResponse(BaseModel):
    """Response containing extracted locations"""
    success: bool
    locations: List[ExtractedLocation] = []
    message: str = ""
    raw_count: int = 0


# =============================================================================
# System Prompt for Gemini
# =============================================================================

EXTRACTION_SYSTEM_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "Data Extraction Specialist" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢

üìå ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á

üìã ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:
1. ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON Array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ markdown formatting (‡πÄ‡∏ä‡πà‡∏ô ```json)
2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö []
3. ‡∏´‡πâ‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
4. category ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô: "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", "‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å", "‡∏ß‡∏±‡∏î", "‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà", "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ"

üìê JSON Schema ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ:
[
  {
    "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
    "category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà",
    "description": "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
    "keywords": ["‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç1", "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç2"],
    "location_guess": "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ)"
  }
]

‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON Array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"""


# =============================================================================
# Helper Functions
# =============================================================================

def _clean_json_response(response_text: str) -> str:
    """Remove markdown code blocks and clean JSON response"""
    # Remove ```json ... ``` blocks
    cleaned = re.sub(r'^```json\s*', '', response_text.strip())
    cleaned = re.sub(r'\s*```$', '', cleaned)
    # Also handle ``` without json
    cleaned = re.sub(r'^```\s*', '', cleaned)
    cleaned = re.sub(r'\s*```$', '', cleaned)
    return cleaned.strip()


def _parse_extraction_response(response_text: str) -> List[Dict[str, Any]]:
    """Parse and validate the extraction response"""
    try:
        cleaned = _clean_json_response(response_text)
        data = json.loads(cleaned)
        
        if not isinstance(data, list):
            logging.warning(f"Expected list, got {type(data)}")
            return []
        
        # Validate each item
        valid_items = []
        for item in data:
            if isinstance(item, dict) and "title" in item:
                valid_items.append({
                    "title": str(item.get("title", "")),
                    "category": str(item.get("category", "‡∏≠‡∏∑‡πà‡∏ô‡πÜ")),
                    "description": str(item.get("description", "")),
                    "keywords": item.get("keywords", []) if isinstance(item.get("keywords"), list) else [],
                    "location_guess": item.get("location_guess") or None
                })
        
        return valid_items
        
    except json.JSONDecodeError as e:
        logging.error(f"‚ùå JSON parse error: {e}\nResponse: {response_text[:500]}")
        return []


async def _call_gemini_extraction(raw_text: str) -> List[Dict[str, Any]]:
    """Call Gemini API with key rotation for text extraction"""
    last_error = None
    
    for attempt in range(MAX_RETRIES):
        try:
            # Get rotated API key
            api_key = gemini_key_manager.get_key()
            if not api_key:
                logging.error("‚ùå No Gemini API keys available")
                return []
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(EXTRACTION_MODEL)
            
            # Build the full prompt
            full_prompt = f"{EXTRACTION_SYSTEM_PROMPT}\n\n--- ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---\n{raw_text}"
            
            # Generate response
            response = await asyncio.to_thread(
                model.generate_content,
                full_prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.1,  # Low temperature for consistent extraction
                    max_output_tokens=4096
                )
            )
            
            if response and response.text:
                logging.info(f"‚úÖ Gemini extraction successful (attempt {attempt + 1})")
                return _parse_extraction_response(response.text)
            else:
                logging.warning("‚ö†Ô∏è Empty response from Gemini")
                return []
                
        except Exception as e:
            last_error = e
            error_str = str(e).lower()
            is_rate_limit = "429" in str(e) or "quota" in error_str or "rate" in error_str
            
            if is_rate_limit:
                logging.warning(f"‚ö†Ô∏è Rate limit hit, rotating key... (attempt {attempt + 1}/{MAX_RETRIES})")
                await asyncio.sleep(1)  # Brief pause before retry
                continue
            else:
                logging.error(f"‚ùå Gemini extraction error: {e}")
                break
    
    logging.error(f"‚ùå All extraction retries failed: {last_error}")
    return []


# =============================================================================
# API Endpoints
# =============================================================================

@router.post("/extract-text", response_model=TextExtractResponse)
async def extract_text_locations(request: TextExtractRequest):
    """
    ü™Ñ Extract tourist locations from raw text using AI
    
    ‡πÉ‡∏ä‡πâ Gemini AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞ extract ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß/‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
    
    - **Input**: Raw text (e.g., copied from PDF, article, website)
    - **Output**: List of extracted locations with title, category, description, keywords
    """
    if not request.raw_text or len(request.raw_text.strip()) < 10:
        raise HTTPException(status_code=400, detail="‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ")
    
    try:
        logging.info(f"üîç [TextImport] Starting extraction from {len(request.raw_text)} characters")
        
        # Call Gemini for extraction
        extracted = await _call_gemini_extraction(request.raw_text)
        
        if not extracted:
            return TextExtractResponse(
                success=True,
                locations=[],
                message="‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ",
                raw_count=0
            )
        
        logging.info(f"‚úÖ [TextImport] Extracted {len(extracted)} locations")
        
        return TextExtractResponse(
            success=True,
            locations=[ExtractedLocation(**loc) for loc in extracted],
            message=f"‡∏û‡∏ö {len(extracted)} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
            raw_count=len(extracted)
        )
        
    except Exception as e:
        logging.error(f"‚ùå [TextImport] Extraction error: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"AI extraction ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e)}"
        )
