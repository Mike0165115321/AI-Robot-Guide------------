# /core/ai_models/news_analyzer_agent.py
"""
News Analyzer Agent: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢ LLM (JSON Mode)
"""

import asyncio
import logging
import json
from typing import Dict, Optional, List
from datetime import datetime, timezone, timedelta

from core.config import settings

logger = logging.getLogger(__name__)


class NewsAnalyzerAgent:
    """Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"""
    
    # Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤)
    ANALYSIS_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô):

‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {title}
‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {body}
‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤: {source}
‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {date}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
{{
    "is_relevant": true/false,
    "category": "disaster|traffic|weather|event|health|general",
    "severity_score": 1-5,
    "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
    "location_name": "‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠ null",
    "valid_hours": 24,
    "action_recommendation": "avoid_route|caution|monitor|info_only"
}}

‡πÄ‡∏Å‡∏ì‡∏ë‡πå severity_score:
1 = ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ/FYI
2 = ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à
3 = ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏£‡∏≤‡∏ö
4 = ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á
5 = ‡∏Ç‡πà‡∏≤‡∏ß‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô/‡∏ß‡∏¥‡∏Å‡∏§‡∏ï

‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ô‡πà‡∏≤‡∏ô ‡πÉ‡∏´‡πâ is_relevant = false"""

    # Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (Batch Mode - 5 ‡∏Ç‡πà‡∏≤‡∏ß/‡∏Ñ‡∏£‡∏±‡πâ‡∏á)
    BATCH_ANALYSIS_PROMPT = """‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON Array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å JSON):

{news_list}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON Array (‡∏ï‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡πà‡∏≤‡∏ß):
[
  {{"news_index": 0, "is_relevant": true, "category": "event", "severity_score": 2, "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô‡πÜ", "location_name": "‡∏≠.‡∏õ‡∏±‡∏ß"}}
]

‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: disaster, traffic, weather, event, health, general
severity_score: 1=‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, 2=‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à, 3=‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç, 4=‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô, 5=‡∏ß‡∏¥‡∏Å‡∏§‡∏ï
‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ô‡πà‡∏≤‡∏ô ‡πÉ‡∏´‡πâ is_relevant = false"""

    def __init__(self):
        self.llm_handler = None
        
    async def _get_llm_handler(self):
        """Lazy load LLM handler"""
        # ‡πÉ‡∏ä‡πâ function-based approach ‡πÅ‡∏ó‡∏ô class
        return True  # Return truthy to indicate ready
    
    async def analyze(self, news_item: Dict) -> Optional[Dict]:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
        
        Args:
            news_item: Dict with title, body, source, date
            
        Returns:
            Analysis result dict or None
        """
        try:
            llm = await self._get_llm_handler()
            if not llm:
                return None
                
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt
            prompt = self.ANALYSIS_PROMPT.format(
                title=news_item.get("title", ""),
                body=news_item.get("body", "")[:500],  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
                source=news_item.get("source", ""),
                date=news_item.get("date", "")
            )
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
            response = await self._call_llm(prompt)
            
            # Parse JSON
            result = self._parse_json_response(response)
            
            if result and result.get("is_relevant", False):
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
                result["original_title"] = news_item.get("title", "")
                result["original_url"] = news_item.get("url", "")
                result["original_source"] = news_item.get("source", "")
                result["analyzed_at"] = datetime.now(timezone.utc).isoformat()
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì valid_until
                valid_hours = result.get("valid_hours", 24)
                result["valid_until"] = (
                    datetime.now(timezone.utc) + timedelta(hours=valid_hours)
                ).isoformat()
                
                logger.info(f"‚úÖ [NewsAnalyzer] ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {result.get('summary', '')[:50]}...")
                return result
            else:
                logger.debug(f"‚è≠Ô∏è [NewsAnalyzer] ‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {news_item.get('title', '')[:30]}...")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå [NewsAnalyzer] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return None
    
    def _parse_json_response(self, response: str) -> Optional[Dict]:
        """Parse JSON ‡∏à‡∏≤‡∏Å LLM response with cleanup"""
        try:
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ JSON block
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            elif "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ [ ] ‡∏´‡∏£‡∏∑‡∏≠ { } ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                if "[" in response and "]" in response:
                    start = response.find("[")
                    end = response.rfind("]") + 1
                    json_str = response[start:end]
                elif "{" in response:
                    start = response.find("{")
                    end = response.rfind("}") + 1
                    if start >= 0 and end > start:
                        json_str = response[start:end]
                    else:
                        return None
                else:
                    return None
            
            # Cleanup JSON common issues
            json_str = self._cleanup_json(json_str)
            
            return json.loads(json_str)
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå [NewsAnalyzer] JSON parse error: {e}")
            return None
    
    def _cleanup_json(self, json_str: str) -> str:
        """Clean up common JSON issues from LLM output"""
        import re
        
        # ‡∏•‡∏ö trailing commas ‡∏Å‡πà‡∏≠‡∏ô ] ‡∏´‡∏£‡∏∑‡∏≠ }
        json_str = re.sub(r',\s*([\]}])', r'\1', json_str)
        
        # ‡∏•‡∏ö newlines ‡πÅ‡∏•‡∏∞ extra spaces ‡πÉ‡∏ô strings ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        json_str = json_str.replace('\n', ' ').replace('\r', '')
        
        # ‡∏•‡∏ö ... (ellipsis) ‡∏ó‡∏µ‡πà LLM ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πÉ‡∏™‡πà‡∏°‡∏≤
        json_str = json_str.replace('...', '')
        
        return json_str.strip()
    
    async def analyze_batch(self, news_items: List[Dict]) -> List[Dict]:
        """
        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô (‡πÉ‡∏ä‡πâ Gemini 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)
        
        Args:
            news_items: List of news items (max 10)
            
        Returns:
            List of relevant analyzed items
        """
        if not news_items:
            return []
            
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 5 ‡∏Ç‡πà‡∏≤‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î API calls ‡πÅ‡∏•‡∏∞‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô rate limit
        items_to_analyze = news_items[:5]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö prompt (‡∏à‡∏≥‡∏Å‡∏±‡∏î body 150 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
        news_list_str = ""
        for i, item in enumerate(items_to_analyze):
            title = item.get("title", "")[:200]
            body = item.get("body", "")[:150]
            news_list_str += f"\n[‡∏Ç‡πà‡∏≤‡∏ß {i}]\n‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {title}\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {body}\n"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt
        prompt = self.BATCH_ANALYSIS_PROMPT.format(news_list=news_list_str)
        
        try:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            response = await self._call_llm(prompt, max_tokens=2048)
            
            # Parse JSON Array
            parsed = self._parse_json_response(response)
            
            if not parsed or not isinstance(parsed, list):
                logger.error("‚ùå [NewsAnalyzer] Batch response ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà JSON Array")
                return []
            
            # Map results ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            results = []
            now = datetime.now(timezone.utc)
            
            for item in parsed:
                if not item.get("is_relevant", False):
                    continue
                    
                idx = item.get("news_index", 0)
                if idx < 0 or idx >= len(items_to_analyze):
                    continue
                    
                original = items_to_analyze[idx]
                
                result = {
                    **item,
                    "original_title": original.get("title", ""),
                    "original_url": original.get("url", ""),
                    "original_source": original.get("source", ""),
                    "analyzed_at": now.isoformat(),
                    "valid_hours": item.get("valid_hours", 24),
                    "valid_until": (now + timedelta(hours=item.get("valid_hours", 24))).isoformat(),
                    "action_recommendation": item.get("action_recommendation", "info_only")
                }
                results.append(result)
            
            logger.info(f"üìä [NewsAnalyzer] ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {len(items_to_analyze)} ‡∏Ç‡πà‡∏≤‡∏ß -> {len(results)} ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (1 Gemini call)")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå [NewsAnalyzer] Batch analyze error: {e}")
            return []
    
    async def _call_llm(self, prompt: str, system_prompt: str = "", max_tokens: int = 1024) -> str:
        """Call LLM with prompt"""
        try:
            from core.ai_models.gemini_handler import get_gemini_response
            return await get_gemini_response(
                user_query=prompt,
                system_prompt=system_prompt or "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô JSON generator ‡∏ï‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô",
                max_tokens=max_tokens
            )
        except Exception as e:
            logger.error(f"‚ùå [NewsAnalyzer] LLM call failed: {e}")
            return ""
    
    async def analyze_weather(self, weather_data: Dict) -> Optional[Dict]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á alert ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        if not weather_data:
            return None
            
        temp = weather_data.get("temperature", 25)
        wind_speed = weather_data.get("wind_speed", 0)
        description = weather_data.get("description", "")
        
        severity = 1
        summary = ""
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥
        if temp > 40:
            severity = max(severity, 4)
            summary = f"üå°Ô∏è ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å {temp}¬∞C - ‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÇ‡∏£‡∏Ñ‡∏•‡∏°‡πÅ‡∏î‡∏î"
        elif temp > 38:
            severity = max(severity, 3)
            summary = f"üå°Ô∏è ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏™‡∏π‡∏á {temp}¬∞C"
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏°
        if wind_speed > 20:
            severity = max(severity, 5)
            summary = f"üí® ‡∏•‡∏°‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å {wind_speed} m/s - ‡∏≠‡∏±‡∏ô‡∏ï‡∏£‡∏≤‡∏¢"
        elif wind_speed > 15:
            severity = max(severity, 4)
            summary = f"üí® ‡∏•‡∏°‡πÅ‡∏£‡∏á {wind_speed} m/s - ‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏•‡πâ‡∏°"
        
        if severity >= 3:
            return {
                "is_relevant": True,
                "category": "weather",
                "severity_score": severity,
                "summary": summary or f"‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®: {description}",
                "location_name": "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô",
                "valid_hours": 6,
                "valid_until": (datetime.now(timezone.utc) + timedelta(hours=6)).isoformat(),
                "action_recommendation": "caution" if severity < 5 else "avoid_route",
                "original_source": weather_data.get("source", "weather_api"),
                "analyzed_at": datetime.now(timezone.utc).isoformat()
            }
        
        return None
    
    async def analyze_air_quality(self, pm25_data: Dict) -> Optional[Dict]:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á alert ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        if not pm25_data:
            return None
            
        severity = pm25_data.get("severity", 1)
        pm25 = pm25_data.get("pm25", 0)
        level = pm25_data.get("aqi_level_th", "‡∏õ‡∏Å‡∏ï‡∏¥")
        
        if severity >= 3:
            action = "monitor" if severity < 4 else "caution"
            summary = f"üå´Ô∏è PM2.5: {pm25} ¬µg/m¬≥ ({level})"
            
            if severity >= 4:
                summary += " - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏ß‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å N95"
            
            return {
                "is_relevant": True,
                "category": "health",
                "severity_score": severity,
                "summary": summary,
                "location_name": pm25_data.get("station_name", "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô"),
                "valid_hours": 3,
                "valid_until": (datetime.now(timezone.utc) + timedelta(hours=3)).isoformat(),
                "action_recommendation": action,
                "original_source": "openaq",
                "analyzed_at": datetime.now(timezone.utc).isoformat()
            }
        
        return None


# Singleton instance
news_analyzer_agent = NewsAnalyzerAgent()
