import asyncio
import logging
import os
import random
import re
import math
import urllib.parse
import json
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

from sentence_transformers import CrossEncoder

# üÜï ‡πÅ‡∏¢‡∏Å Gemini ‡πÅ‡∏•‡∏∞ Groq handlers ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏±‡∏ô
from core.ai_models.gemini_handler import get_gemini_response
from core.ai_models.groq_handler import get_groq_response, get_small_talk_response
from core.ai_models.query_interpreter import QueryInterpreter
from core.ai_models.youtube_handler import youtube_handler_instance
from core.config import settings
from .handlers.analytics_handler import AnalyticsHandler
from core.database.mongodb_manager import MongoDBManager
from core.database.qdrant_manager import QdrantManager
from core.tools.image_search_tool import image_search_tool_instance
from core.services.calculator_service import calculator_service  # üßÆ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç Python
from utils.helper_functions import create_synthetic_document
from .services.session_manager import SessionManager
from .services.navigation_service import NavigationService
from .services.prompt_engine import PromptEngine
from core.services.image_service import ImageService

BACKEND_ROOT = Path(__file__).resolve().parent.parent.parent

def construct_full_image_url(image_path: str | None) -> str | None:
    if not image_path: return None
    if image_path.startswith(('http://', 'https://')):
        return image_path
    if image_path.startswith('/'):
        return f"http://{settings.API_HOST}:{settings.API_PORT}{image_path}"
    return image_path

class RAGOrchestrator:
    def __init__(
        self,
        mongo_manager: MongoDBManager,
        qdrant_manager: QdrantManager,
        query_interpreter: QueryInterpreter,
    ):
        logging.info("‚öôÔ∏è  ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG Orchestrator (Refactored V8.1)...")
        self.mongo_manager = mongo_manager
        self.qdrant_manager = qdrant_manager
        self.query_interpreter = query_interpreter
        self.session_manager = SessionManager(mongo_manager)
        self.prompt_engine = PromptEngine()
        self.nav_service = NavigationService(mongo_manager, self.prompt_engine)
        self.image_service = ImageService(mongo_manager)

        self.reranker_model_name = settings.RERANKER_MODEL_NAME
        self.device = settings.DEVICE

        logging.info(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Re-ranker ('{self.reranker_model_name}' ‡∏ö‡∏ô '{self.device}')...")
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• CrossEncoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Reranking
        # ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô
        self.reranker = CrossEncoder(self.reranker_model_name, device=self.device)
        logging.info("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Re-ranker ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

        self.log_collection = self.mongo_manager.get_collection("query_logs")
        
        self.analytics_handler = AnalyticsHandler(
            mongo_manager=self.mongo_manager,
            query_interpreter=self.query_interpreter,
            orchestrator_callback=self.answer_query
        )
        logging.info("‚úÖ RAG Orchestrator ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    def _prepare_source_and_image_data(self, docs_to_show: List[Dict[str, Any]]) -> Dict[str, Any]:
        source_info: List[dict] = []
        static_image_gallery: List[str] = []
        processed_prefixes = set()
        for doc in docs_to_show:
            if not doc: continue
            prefix = doc.get("metadata", {}).get("image_prefix")
            doc_images = []
            if prefix and prefix not in processed_prefixes:
                found_images = self.image_service.find_all_images_by_prefix(prefix)
                if found_images:
                    doc_images.extend(found_images)
                    for img_url in found_images:
                        if img_url not in static_image_gallery:
                            static_image_gallery.append(img_url)
                    processed_prefixes.add(prefix)
            source_info.append({
                "title": doc.get("title", "N/A"),
                "summary": doc.get("summary", ""),
                "image_urls": doc_images[: settings.SOURCE_CARD_IMAGE_LIMIT],
            })
        return {"source_info": source_info, "image_gallery": static_image_gallery}

    async def _handle_welcome_flow(self, session_id: Optional[str] = None, **kwargs) -> dict:
        # üÜï Dynamic Greeting (Requested by User)
        # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Fixed Text ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• 8B (Small Talk) ‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏≠‡∏á‡πÄ‡∏•‡∏¢
        corrected_query = kwargs.get('corrected_query') or "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ"
        
        logging.info(f"üëã [Welcome] Generating Dynamic Greeting for: '{corrected_query}'")
        final_answer = await get_small_talk_response(user_query=corrected_query)
        
        return {
            "answer": final_answer,
            "action": None, # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Force Analytics ‡πÅ‡∏•‡πâ‡∏ß
            "action_payload": None, "image_url": None, "image_gallery": [], "sources": [],
        }

    def _map_frontend_intent(self, frontend_intent: str) -> str:
        """
        üÜï ‡πÅ‡∏õ‡∏•‡∏á frontend intent ‡πÄ‡∏õ‡πá‡∏ô internal intent
        ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå - ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î tokens!
        """
        intent_map = {
            "MUSIC": "PLAY_MUSIC",
            "NAVIGATION": "NAVIGATE_TO",
            "FAQ": "INFORMATIONAL",
            "GENERAL": "INFORMATIONAL",
            "WELCOME": "WELCOME_FLOW",
            # ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢ widget ‡∏ù‡∏±‡πà‡∏á frontend
        }
        return intent_map.get(frontend_intent.upper(), "INFORMATIONAL")

    async def _handle_small_talk(self, corrected_query: str, **kwargs) -> dict:
        final_answer = await get_small_talk_response(user_query=corrected_query)
        return {"answer": final_answer, "action": None, "sources": [], "image_url": None, "image_gallery": []}

    async def _handle_calculate(self, corrected_query: str, **kwargs) -> dict:
        """
        üßÆ Calculator handler - Hybrid Mode:
        Pure math ‚Üí Python ‡∏ï‡∏£‡∏á | Text+math ‚Üí AI 70B ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        """
        return await calculator_service.calculate(corrected_query)

    async def _handle_play_music(self, corrected_query: str = "", **kwargs) -> dict:
        """
        üéµ Play music handler - ‡πÉ‡∏ä‡πâ corrected_query ‡πÄ‡∏õ‡πá‡∏ô search term ‡∏ï‡∏£‡∏á‡πÜ
        Frontend ‡∏™‡πà‡∏á song name ‡∏°‡∏≤‡πÉ‡∏ô query ‡πÅ‡∏•‡πâ‡∏ß
        """
        search_query = corrected_query.strip() if corrected_query else ""
        
        # ‡∏ñ‡πâ‡∏≤ query ‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        generic_triggers = ["‡πÄ‡∏û‡∏•‡∏á", "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏û‡∏•‡∏á", "‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á", "music", "song", "‡∏≠‡∏¢‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á", ""]
        if search_query in generic_triggers:
            return {
                "answer": "‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞! ‡∏≠‡∏¢‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏≠‡∏∞‡πÑ‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏´‡∏ô ‡∏ö‡∏≠‡∏Å‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞ üéß",
                "action": "PROMPT_FOR_SONG_INPUT",
                "action_payload": {"placeholder": "‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏¥‡∏ö‡πÜ, ‡∏õ‡∏π‡πà‡∏à‡πã‡∏≤‡∏ô ‡∏•‡∏≠‡∏á‡πÑ‡∏°‡∏Ñ‡πå..."},
                "sources": [], "image_url": None, "image_gallery": []
            }
        
        logging.info(f"üéµ [Music] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á‡πÉ‡∏ô YouTube ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{search_query}'")
        search_results = await youtube_handler_instance.search_music(query=search_query)
        
        if not search_results:
            return {
                "answer": f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏´‡∏≤‡πÄ‡∏û‡∏•‡∏á '{search_query}' ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏•‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡∏î‡∏π‡∏°‡∏±‡πâ‡∏¢‡∏Ñ‡∏∞?",
                "action": None,
                "action_payload": None,
                "sources": [], "image_url": None, "image_gallery": []
            }
        
        return {
            "answer": f"‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏Ñ‡πà‡∏∞! ‡πÄ‡∏û‡∏•‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö **'{search_query}'**",
            "action": "SHOW_SONG_CHOICES", 
            "action_payload": search_results,
            "sources": [], "image_url": None, "image_gallery": []
        }

    # _handle_system_command ‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏≠‡∏≠‡∏Å - ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢ frontend widget ‡πÅ‡∏•‡πâ‡∏ß

    async def _handle_informational(
        self, corrected_query: str, entity: Optional[str], sub_queries: List[str], mode: str, 
        turn_count: int = 1, session_id: Optional[str] = None, ai_mode: str = "fast", 
        original_query: str = None,
        interpretation: Dict[str, Any] = None,
        **kwargs
    ) -> dict:
        interpretation = interpretation or kwargs.get("interpretation", {})
        
        unique_queries = interpretation.get("sub_queries") or [corrected_query]
        entity = interpretation.get("entity")
        
        print(f"DEBUG PRINT: _handle_informational CALLED. Entity=[{entity}]")
        logging.info(f"üîé [DEBUG] _handle_informational Called. Args Entity: {entity}, Kwargs Interpretation Keys: {interpretation.keys()}")
        if entity:
             logging.info(f"üîé [DEBUG] Entity is present: '{entity}'")
        else:
             logging.info(f"üîé [DEBUG] Entity is NONE or EMPTY.")
        
        
        # üõ°Ô∏è Construct Metadata Filter (Location + Category)
        # 2024-12-16: User requested to DISABLE location/district filtering for simplicity.
        # location_filter = interpretation.get("location_filter", {}) 
        location_filter = {} # Force empty to disable
        
        category = interpretation.get("category")
        
        metadata_filter = location_filter.copy()
        if category:
            metadata_filter["category"] = category
            logging.info(f"üè∑Ô∏è [Filter] Applying Category Filter: {category}")
        
        # üÜï [SMART] Always exclude district/province data from search results
        # ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î" ‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        EXCLUDED_CATEGORIES = [
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à"
        ]
        metadata_filter["exclude_categories"] = EXCLUDED_CATEGORIES
        logging.info(f"üö´ [Filter] Excluding categories: {EXCLUDED_CATEGORIES}")

        # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Retrieval)
        # ‡πÉ‡∏ä‡πâ Qdrant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ (Semantic Search)
        # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å sub-query ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°
        mongo_ids_from_search = []
        qdrant_results_combined = []
        
        logging.info(f"üîé [RAG] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•... (Queries: {unique_queries}, Filter: {metadata_filter})")

        # 1.5 SMART FEATURE: Direct Entity Search
        # If Interpreter detected an entity, try to find it directly in DB (Accuracy Boost)
        # This bypasses Semantic Search limitations for specific names.
        found_direct_entity = False
        if entity:
             logging.info(f"üéØ [RAG] Specific Entity Detected: '{entity}' - Attempting Direct DB Lookup...")
             direct_doc = await asyncio.to_thread(self.mongo_manager.get_location_by_title, entity)
             
             if direct_doc:
                 logging.info(f"‚úÖ [RAG] Found Direct Match: {direct_doc.get('title')}")
                 found_direct_entity = True
                 mock_result = {
                    "payload": {
                        "mongo_id": str(direct_doc.get("_id")),
                        "title": direct_doc.get("title"),
                        "summary": direct_doc.get("summary"),
                        "category": direct_doc.get("category"),
                        "slug": direct_doc.get("slug"),
                        "location_data": direct_doc.get("location_data"),
                        "image_urls": direct_doc.get("image_urls", []),
                        "metadata": direct_doc.get("metadata", {}),
                        "is_direct_match": True # Mark as direct match
                    },
                    "score": 1.5 # Boost score above everything else (Typical vector score < 1.0)
                 }
                 qdrant_results_combined.append(mock_result)

        # üî• SMART FEATURE: Trending Recommendations for Broad Queries
        # If no specific entity is requested AND no specific filters (except maybe general category),
        # we consider it a "Broad Query" and inject recommended tourist attractions.
        is_broad_query = (not found_direct_entity) and (entity is None) and (not location_filter)
        
        if is_broad_query:
            logging.info("üî• [RAG] Broad Query Detected! Fetching Recommended Attractions...")
            try:
                # üÜï ‡πÉ‡∏ä‡πâ get_recommended_attractions ‡πÅ‡∏ó‡∏ô get_trending_locations
                # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏≠‡∏≥‡πÄ‡∏†‡∏≠
                recommended_docs = await asyncio.to_thread(
                    self.mongo_manager.get_recommended_attractions, 
                    limit=5
                )
                
                if recommended_docs:
                    logging.info(f"üéØ [Recommended] Found {len(recommended_docs)} attractions")
                    for doc in recommended_docs:
                        logging.info(f"   - {doc.get('title')} ({doc.get('category')})")
                        mock_result = {
                            "payload": {
                                "mongo_id": str(doc.get("_id")),
                                "title": doc.get("title"),
                                "summary": doc.get("summary"),
                                "category": doc.get("category"),
                                "slug": doc.get("slug"),
                                "location_data": doc.get("location_data"),
                                "image_urls": doc.get("image_urls", []),
                                "metadata": doc.get("metadata", {}),
                                "is_recommended": True  # Mark as recommended
                            },
                            "score": 0.85  # Good score but let semantic match win if very specific
                        }
                        qdrant_results_combined.append(mock_result)
                else:
                    logging.warning("‚ö†Ô∏è [Recommended] No attractions found, falling back to semantic search")
            except Exception as e:
                logging.error(f"‚ùå [RAG] Error fetching recommended attractions: {e}")

        for q in unique_queries:
            # Pass metadata_filter to search_similar
            qdrant_results = await self.qdrant_manager.search_similar(
                query_text=q, 
                top_k=settings.QDRANT_TOP_K,
                metadata_filter=metadata_filter # üÜï Apply Merged Filter
            )
            qdrant_results_combined.extend(qdrant_results)
            for res in qdrant_results:
                if res.payload and res.payload.get("mongo_id"):
                    mongo_ids_from_search.append(res.payload.get("mongo_id"))

        # [‡πÅ‡∏ú‡∏ô‡∏™‡∏≥‡∏£‡∏≠‡∏á] ‡∏´‡∏≤‡∏Å Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡πà‡∏°) ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB ‡πÅ‡∏ó‡∏ô
        if not qdrant_results_combined:
            logging.info("‚ö†Ô∏è [RAG] Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB...")
            # ‡πÉ‡∏ä‡πâ entity ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ corrected_query
            search_term = entity if entity else corrected_query
            
            # TODO: Improve MongoDB Fallback to support filter (Optional for now)
            logging.info(f"‚ö†Ô∏è [RAG] Qdrant ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô MongoDB ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤: '{search_term}'")
            mongo_results = await asyncio.to_thread(self.mongo_manager.get_location_by_title, search_term)
            if mongo_results:
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å MongoDB ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö payload ‡∏Ç‡∏≠‡∏á Qdrant
                # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á Qdrant ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏µ 'payload' ‡πÅ‡∏•‡∏∞ 'score'
                # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ö‡∏ö Qdrant ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
                mock_qdrant_result = {
                    "payload": {
                        "mongo_id": str(mongo_results.get("_id")), # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏° _id ‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
                        "title": mongo_results.get("title"),
                        "summary": mongo_results.get("summary"),
                        "category": mongo_results.get("category"),
                        "slug": mongo_results.get("slug"),
                        "location_data": mongo_results.get("location_data"),
                        "image_urls": mongo_results.get("image_urls", []),
                        "metadata": mongo_results.get("metadata", {})
                    },
                    "score": 1.0 # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≥‡∏£‡∏≠‡∏á
                }
                qdrant_results_combined.append(mock_qdrant_result)
                mongo_ids_from_search.append(str(mongo_results.get("_id")))
                logging.info(f"‚úÖ [RAG] ‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÉ‡∏ô MongoDB: {mongo_results.get('title')}")


        unique_ids = list(dict.fromkeys(mongo_ids_from_search))
        
        # Capture Trending IDs to re-apply metadata later
        # FIX: Check if res is object (ScoredPoint) or dict
        def get_payload(res):
            if hasattr(res, 'payload'): return res.payload
            if isinstance(res, dict): return res.get('payload', {})
            return {}

        trending_ids = {get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                        if get_payload(res).get('is_trending')}
                        
        direct_match_ids = {get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                            if get_payload(res).get('is_direct_match')}

        # Re-populate unique_ids from ALL results including trending
        all_mongo_ids = [get_payload(res).get('mongo_id') for res in qdrant_results_combined 
                         if get_payload(res).get('mongo_id')]
        unique_ids = list(dict.fromkeys(all_mongo_ids))

        if not unique_ids:
            return {"answer": "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", "action": None, "sources": [], "image_url": None, "image_gallery": []}

        retrieved_docs = await asyncio.to_thread(self.mongo_manager.get_locations_by_ids, unique_ids)
        if not retrieved_docs:
            return {"answer": "‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏∞", "action": None, "sources": [], "image_url": None, "image_gallery": []}
            
        # üÜï Re-inject Trending & Score Info
        # Note: We can't rely on Qdrant scores for trending items (they are mock scores)
        # We just mark them.
        for doc in retrieved_docs:
            doc_id = str(doc.get('_id'))
            if doc_id in trending_ids:
                doc['is_trending'] = True
                doc['title'] = f"üî• {doc.get('title')}" # Hack: Add fire to title for Reranker context too
            if doc_id in direct_match_ids:
                doc['is_direct_match'] = True
                doc['title'] = f"üéØ {doc.get('title')}" # Hack: Add target to title
        
        # TODO: Consider synthetic doc creation - we might need to update it
        # from core.ai_models.utils.summarizer import create_synthetic_document # Removed as it's imported globally now
        docs_with_synthetic = await asyncio.to_thread(lambda docs: [(doc, create_synthetic_document(doc)) for doc in docs], retrieved_docs)
        # üîÑ [RERANKING] ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (User Query, Document) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Reranker ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á 
        sentence_pairs = [[corrected_query, synthetic_doc] for doc, synthetic_doc in docs_with_synthetic]
        
        # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô (Score) ‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏¢‡∏≠‡∏∞‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
        scores = await asyncio.to_thread(self.reranker.predict, sentence_pairs, show_progress_bar=False)
        
        # ÔøΩÔ∏è [Score Boosting] ‡∏î‡∏±‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Trending/Direct ‡πÉ‡∏´‡πâ‡∏ä‡∏ô‡∏∞ Semantic ‡πÄ‡∏™‡∏°‡∏≠
        final_scores = []
        for score, (doc, _) in zip(scores, docs_with_synthetic):
            boosted_score = float(score)
            if doc.get('is_direct_match'):
                boosted_score = max(boosted_score, 0.99) # Direct Match = Almost 1.0
            elif doc.get('is_trending'):
                # Trending items get a floor, but can go higher if relevant
                boosted_score = max(boosted_score, 0.85) 
            final_scores.append(boosted_score)
        
        # ÔøΩüîç [Debug Log] ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Reranking ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        logging.info(f"üìä [Reranking] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {len(final_scores)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£...")
        for i, (score, (doc, _)) in enumerate(zip(final_scores, docs_with_synthetic)):
            logging.info(f"   üîπ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {doc.get('title')} | ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {score:.4f} | Trending: {doc.get('is_trending', False)} | Direct: {doc.get('is_direct_match', False)}")

        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Boosted (‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢)
        reranked_results = sorted(zip(final_scores, docs_with_synthetic), key=lambda x: x[0], reverse=True)
        
        # üîç [Debug Log] ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö (Top 3)
        logging.info(f"üèÜ [Reranking] 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏´‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà:")
        for i, (score, (doc, _)) in enumerate(reranked_results[:3]):
             logging.info(f"   ü•á #{i+1}: {doc.get('title')} (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: {score:.4f})")

        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î Top K ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
        top_k = settings.TOP_K_RERANK_VOICE if mode == "voice" else settings.TOP_K_RERANK_TEXT
        
        # üõ°Ô∏è [Self-Correction] Confidence Check
        is_low_confidence = False
        if reranked_results:
            top_score = reranked_results[0][0]
            # Trust Trending AND Direct Matches
            has_trusted_source = any(d.get('is_trending') or d.get('is_direct_match') for _, (d, _) in reranked_results[:top_k])
            
            if top_score < settings.RAG_CONFIDENCE_THRESHOLD and not has_trusted_source:
                # Only flag low confidence if NO trusted items are in top K
                # (Trending/Direct items are high value regardless of semantic score)
                is_low_confidence = True
                logging.warning(f"‚ö†Ô∏è [Low Confidence] ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ({top_score:.4f}) ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå ({settings.RAG_CONFIDENCE_THRESHOLD})")
                
                # üìù [Log Quality] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÑ‡∏õ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á (Active Learning)
                logging.info(f"üìâ [Quality Log] Triggered Low Confidence for query: '{corrected_query}'")
        
        final_docs = [doc for score, (doc, _) in reranked_results[:top_k]]
        
        context_str = ""
        if final_docs:
            context_parts = []
            for i, doc in enumerate(final_docs, 1):
                doc_text = create_synthetic_document(doc)
                if doc.get('is_trending'):
                    doc_text = f"üî• [POPULAR/TRENDING] ‡∏ô‡∏µ‡πà‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ: {doc_text}"
                context_parts.append(f"[Document {i}]\nTitle: {doc.get('title')}\nInfo: {doc_text}")
            context_str = "\n\n----------------\n\n".join(context_parts)

        history = []
        if session_id:
            session = await self.session_manager.get_session(session_id)
            history = session.get("history", [])

        prompt_dict = self.prompt_engine.build_rag_prompt(
            user_query=original_query or corrected_query, # üÜï ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 
            context=context_str, 
            history=history,
            ai_mode=ai_mode,  # üÜï ‡∏™‡πà‡∏á mode ‡πÑ‡∏õ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            is_low_confidence=is_low_confidence # üõ°Ô∏è [Self-Correction]
        )
        
        messages = [
            {"role": "system", "content": prompt_dict["system"]},
            {"role": "user", "content": prompt_dict["user"]}
        ]

        logging.info(f"ü§ñ [LLM] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î AI: {ai_mode}")
        
        if ai_mode == "detailed":
            # ‡πÉ‡∏ä‡πâ Gemini ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 
            raw_answer = await get_gemini_response(
                user_query=prompt_dict["user"],
                system_prompt=prompt_dict["system"],
                max_tokens=8192
            )
        else:
            # ‡πÉ‡∏ä‡πâ Groq/Llama ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
            try:
                raw_answer = await get_groq_response(
                    messages=messages,
                    model_name=settings.GROQ_LLAMA_MODEL
                )
            except Exception as e:
                logging.error(f"‚ö†Ô∏è [Groq] ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e} ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Gemini...")
                # ‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ Gemini ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                raw_answer = await get_gemini_response(
                    user_query=prompt_dict["user"],
                    system_prompt=prompt_dict["system"],
                    max_tokens=8192
                )
        
        final_answer_with_images = await self.image_service.inject_images_into_text(raw_answer)
        
        docs_to_show = final_docs[:5]
        prepared_data = self._prepare_source_and_image_data(docs_to_show)
        static_gallery = prepared_data["image_gallery"]
        
        if len(static_gallery) < settings.IMAGE_FALLBACK_THRESHOLD and final_docs:
            search_q = f"{final_docs[0].get('title')} ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô" 
            try:
                google_imgs = await image_search_tool_instance.get_image_urls(search_q, max_results=settings.GOOGLE_IMAGE_MAX_RESULTS)
                for url in google_imgs:
                    if url not in static_gallery: static_gallery.append(url)
            except Exception as e:
                logging.error(f"‚ùå ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û Google ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

        return {
            "answer": final_answer_with_images,
            "action": None,
            "image_url": None, 
            "image_gallery": static_gallery[:settings.FINAL_GALLERY_IMAGE_LIMIT],
            "sources": prepared_data["source_info"],
            "_primary_topic": final_docs[0].get("title") if final_docs else None # ‡∏™‡πà‡∏á Topic ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å State
        }

    async def get_navigation_list(self, user_lat: float = None, user_lon: float = None) -> List[Dict[str, Any]]:
        try:
            collection = self.mongo_manager.get_collection("nan_locations")
            if collection is None:
                logging.warning("‚ö†Ô∏è [NavList] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ MongoDB ‡πÑ‡∏î‡πâ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á")
                return []

            docs = await asyncio.to_thread(lambda: list(collection.find(
                {"doc_type": "Location"}, 
                {"title":1, "slug":1, "topic":1, "summary":1, "category":1, "location_data":1, "metadata":1, "_id":0}
            )))
            
            if user_lat and user_lon:
                docs = self.nav_service.sort_locations_by_distance(docs, user_lat, user_lon)
            
            for doc in docs:
                imgs = self.image_service.get_location_images(doc)
                doc["image_urls"] = [imgs[0]] if imgs else []
            
            return docs
        except Exception as e:
            logging.error(f"‚ùå [NavList] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return []

    async def handle_get_directions(self, entity_slug: str, user_lat: float = None, user_lon: float = None) -> dict:
        return await self.nav_service.handle_get_directions(entity_slug, user_lat, user_lon)
    
    async def answer_query(self, query: str, mode: str = "text", session_id: Optional[str] = None, ai_mode: str = "fast", frontend_intent: str = None, slug: Optional[str] = None, entity_query: Optional[str] = None, **kwargs) -> dict:
        """
        ai_mode: 'fast' = Llama/Groq, 'detailed' = Gemini
        frontend_intent: 'GENERAL' | 'MUSIC' | 'NAVIGATION' | 'FAQ' (‡∏à‡∏≤‡∏Å Frontend)
        """
        session_data = await self.session_manager.get_session(session_id)
        current_turn = session_data.get("turn_count", 0) + 1
        history = session_data.get("history", []) 
        
        if session_id and session_data.get("awaiting") == "analytics_origin_or_topic":
            self.session_manager.collection.update_one({"session_id": session_id}, {"$unset": {"awaiting": ""}})
            return await self.analytics_handler.handle_analytics_response(query, session_id, mode)

        start_time = time.perf_counter() # ‚è±Ô∏è Start Timer

        logging.info(f"üîÑ [Session] ID: {session_id} | ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà: {current_turn} | ‡πÇ‡∏´‡∏°‡∏î AI: {ai_mode} | ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏à‡∏≤‡∏Å Frontend: {frontend_intent}")

        # üÜï ‡πÉ‡∏ä‡πâ frontend_intent ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤
        # Note: "LINE" frontend_intent should use LLM analysis to detect music/navigation intents
        if frontend_intent and frontend_intent not in ["GENERAL", "LINE", None]:
            # Frontend ‡∏ö‡∏≠‡∏Å intent ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢!
            intent = self._map_frontend_intent(frontend_intent)
            corrected_query = query
            entity = None  # ‡∏à‡∏∞‡∏´‡∏≤‡∏à‡∏≤‡∏Å query ‡∏´‡∏£‡∏∑‡∏≠ Qdrant search
            
            # üöÄ [Direct Bypass] ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ intent NAVIGATE_TO + slug/entity_query ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡∏¢!
            if intent == "NAVIGATE_TO":
                 target_entity = slug or entity_query or query
                 if target_entity:
                     logging.info(f"üèéÔ∏è [Quick Nav] ‡∏Ç‡πâ‡∏≤‡∏° Logic ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á: '{target_entity}'")
                     return await self.handle_get_directions(entity_slug=target_entity)

            logging.info(f"üöÄ [Intent] ‡πÉ‡∏ä‡πâ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏à‡∏≤‡∏Å FRONTEND: {intent}")
            interpretation = {"intent": intent, "corrected_query": query, "entity": entity, "is_complex": False, "sub_queries": [query], "location_filter": {}}
        else:
            # ‡πÉ‡∏ä‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡πÅ‡∏•‡∏∞ Filter (Dynamic)
            logging.info(f"üß† [Router] ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Query Interpreter ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Location Filter...")
            interpretation = await self.query_interpreter.interpret_and_route(query)
            intent = interpretation.get("intent", "INFORMATIONAL")
            corrected_query = interpretation.get("corrected_query", query)
            entity = interpretation.get("entity")
            # Note: location_filter is inside interpretation and handled in _handle_informational via interpretation object if passed, 
            # BUT _handle_informational signature expects separate args currently? 
            # Wait, verify _handle_informational signature again.
            
            logging.info(f"üö¶ ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤: {intent} | ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô: {corrected_query} | Location Filter: {interpretation.get('location_filter')}")
        
        import sys
        
        navigation_keywords = ["‡∏ô‡∏≥‡∏ó‡∏≤‡∏á", "‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á", "‡∏û‡∏≤‡πÑ‡∏õ", "‡∏Ç‡∏≠‡∏ó‡∏≤‡∏á", "‡πÑ‡∏õ‡∏¢‡∏±‡∏á", "‡πÑ‡∏õ‡∏ß‡∏±‡∏î", "‡πÑ‡∏õ‡∏ó‡∏µ‡πà"]
        is_nav_request = any(kw in corrected_query for kw in navigation_keywords)
        
        if is_nav_request:
            target_entity = entity
            
            if not target_entity and session_id:
                last_topic = await self.session_manager.get_last_topic(session_id)
                if last_topic:
                    logging.info(f"üß† [Memory] ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡∏™‡∏±‡∏ô‡∏ô‡∏¥‡∏©‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: '{last_topic}'")
                    target_entity = last_topic
                else:
                    return {"answer": "‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞! ‡πÅ‡∏ï‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏´‡πâ **‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô?** üòä", "action": None, "sources": [], "image_url": None}

            if target_entity:
                logging.info(f"üó∫Ô∏è [Smart Router] ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{target_entity}'")
                return await self.handle_get_directions(
                    entity_slug=target_entity, 
                    user_lat=kwargs.get('user_lat', 0.0),
                    user_lon=kwargs.get('user_lon', 0.0)
                )
        
        # üßÆ [Calculator Detection] ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Å‡πà‡∏≠‡∏ô (Hybrid Mode)
        # Pure math ‚Üí Python ‡∏ï‡∏£‡∏á | Text+math ‚Üí AI 70B ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        if calculator_service.is_calculator_query(query):
            logging.info(f"üßÆ [Calculator] ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå: '{query}'")
            return await calculator_service.calculate(query)
        
        handler_map = {
            "WELCOME_GREETING": self._handle_welcome_flow,
            "SMALL_TALK": self._handle_small_talk,  # üëà [‡∏à‡∏∏‡∏î‡πÅ‡∏¢‡∏Å] ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô SMALL_TALK ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏•‡πá‡∏Å (Llama 8B)
            "PLAY_MUSIC": self._handle_play_music,
            "CALCULATE": self._handle_calculate,  # üßÆ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏•‡∏Ç Python
            "INFORMATIONAL": self._handle_informational,
        }
        handler = handler_map.get(intent, self._handle_informational)
        
        response = await handler(
            corrected_query=corrected_query,
            entity=entity,
            is_complex=interpretation.get("is_complex", False),
            sub_queries=interpretation.get("sub_queries", []),
            mode=mode,
            session_id=session_id,
            turn_count=current_turn,
            ai_mode=ai_mode,   # üÜï ‡∏™‡πà‡∏á ai_mode ‡πÑ‡∏õ‡∏¢‡∏±‡∏á handlers
            interpretation=interpretation, # üÜï Send full interpretation object (with location_filter)
            original_query=query, # üÜï ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢
            **kwargs
        )

        end_time = time.perf_counter()
        processing_time = round(end_time - start_time, 2)
        response["processing_time"] = processing_time
        
        logging.info(f"‚è±Ô∏è [Performance] Total Processing Time: {processing_time}s")


        if session_id:
            primary_topic = response.pop("_primary_topic", None) 
            await self.session_manager.update_turn(
                session_id, 
                user_query=query, 
                ai_response=response.get("answer", ""), 
                topic=primary_topic
            )
            
            # üöÄ [Analytics] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
            if primary_topic:
                await self.analytics_handler.log_interest_event(session_id, primary_topic, query)
            
        return response