# /core/services/ai_mapper_service.py
"""
AI Mapper Service: ‡πÉ‡∏ä‡πâ Gemini AI ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏•‡∏á Target Fields
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI-Powered Smart ETL System
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö API Key Rotation ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error (429)
- ‡∏°‡∏µ Retry Logic ‡∏û‡∏£‡πâ‡∏≠‡∏° Exponential Backoff
"""

import json
import asyncio
from typing import List, Dict, Any, Optional
import google.generativeai as genai
from core.config import settings
from core.ai_models.key_manager import gemini_key_manager


class AIMapperService:
    """
    Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI-powered data transformation
    ‡πÉ‡∏ä‡πâ Gemini ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏¥‡∏ö
    ‡∏û‡∏£‡πâ‡∏≠‡∏° API Key Rotation ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error
    """
    
    MAX_RETRIES = 4  # ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 4 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏´‡∏°‡∏∏‡∏ô‡∏Ñ‡∏£‡∏ö 4 keys)
    
    def __init__(self):
        self.current_key = None
        self.model = None
        self._configure_with_next_key()
    
    def _configure_with_next_key(self) -> bool:
        """‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ API Key ‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
        try:
            new_key = gemini_key_manager.get_key()
            if not new_key:
                print("‚ùå [AIMapperService] ‡πÑ‡∏°‡πà‡∏°‡∏µ API keys ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏¢‡∏π‡πà!")
                return False
            
            self.current_key = new_key
            genai.configure(api_key=new_key)
            self.model = genai.GenerativeModel(settings.GEMINI_MODEL)
            
            # ‡πÅ‡∏™‡∏î‡∏á key ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡∏ã‡πà‡∏≠‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡πâ‡∏≤‡∏¢)
            masked_key = new_key[:8] + "..." + new_key[-4:]
            print(f"üîë [AIMapperService] ‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏ä‡πâ key: {masked_key}")
            return True
            
        except Exception as e:
            print(f"‚ùå [AIMapperService] ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
            return False
    
    def _build_prompt(self, raw_data: Dict[str, Any], target_fields: List[str]) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô text ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        raw_text_parts = []
        for key, value in raw_data.items():
            if value and str(value).strip():
                raw_text_parts.append(f"{key}: {value}")
        raw_text = "\n".join(raw_text_parts)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á field descriptions - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Core ‡πÅ‡∏•‡∏∞ Detail fields
        field_descriptions = {
            # Core Fields (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Schema)
            "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà/‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤",
            "category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å, ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡∏ß‡∏±‡∏î",
            "topic": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà, ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
            "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
            "keywords": "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma",
            # Detail Fields
            "detail_overview": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤",
            "detail_location": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà ‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á",
            "detail_hours_contact": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£ Line Facebook",
            "detail_highlights": "‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏•‡∏≤‡∏î",
            "detail_price": "‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏° ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "detail_atmosphere": "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
            "detail_facilities": "‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ WiFi ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥",
            "detail_tips": "‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ fields ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        fields_list = []
        for field in target_fields:
            desc = field_descriptions.get(field, field)
            fields_list.append(f'  "{field}": "{desc}"')
        fields_json_hint = "{\n" + ",\n".join(fields_list) + "\n}"
        
        prompt = f"""[CONTEXT]
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Data Extraction Expert ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Structured JSON
‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö fields ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î

[INPUT DATA - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö]
---
{raw_text}
---

[TARGET FIELDS - ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ extract]
{fields_json_hint}

[INSTRUCTIONS]
1. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
2. Extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏•‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ field ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
3. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏õ‡∏¥‡∏î 8-5 ‡πÇ‡∏°‡∏á" ‚Üí detail_hours_contact: "08:00-17:00"
4. ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö field ‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤ null
5. **‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö**

[OUTPUT FORMAT]
‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å JSON
"""
        return prompt
    
    async def transform_row(self, raw_data: Dict[str, Any], target_fields: List[str]) -> Dict[str, Any]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö 1 ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô structured data ‡∏ï‡∏≤‡∏° target fields
        ‡∏û‡∏£‡πâ‡∏≠‡∏° retry logic ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ Quota Error (429)
        """
        if not self.model:
            if not self._configure_with_next_key():
                return {field: "[Error: No API key available]" for field in target_fields}
        
        prompt = self._build_prompt(raw_data, target_fields)
        
        for attempt in range(self.MAX_RETRIES):
            try:
                # Call Gemini API
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt
                )
                
                # Clean and parse response
                response_text = response.text.strip()
                
                # Remove markdown code block if present
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                # Parse JSON
                extracted = json.loads(response_text)
                
                # Ensure all target fields are present
                result = {}
                for field in target_fields:
                    result[field] = extracted.get(field)
                
                return result
                
            except json.JSONDecodeError as je:
                print(f"‚ùå [AIMapperService] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á JSON: {je}")
                return {field: "[Error: Invalid JSON response]" for field in target_fields}
                
            except Exception as e:
                error_str = str(e)
                
                # Check if it's a Quota Error (429)
                if "429" in error_str or "quota" in error_str.lower() or "exceeded" in error_str.lower():
                    print(f"‚ö†Ô∏è [AIMapperService] Quota ‡πÄ‡∏ï‡πá‡∏° (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1}/{self.MAX_RETRIES}), ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô key...")
                    
                    # Rotate to next API key
                    if self._configure_with_next_key():
                        # Exponential backoff: 1s, 2s, 4s, 8s
                        wait_time = min(2 ** attempt, 8)
                        print(f"‚è≥ ‡∏£‡∏≠ {wait_time} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà...")
                        await asyncio.sleep(wait_time)
                        continue
                    else:
                        return {field: "[Error: All API keys exhausted]" for field in target_fields}
                else:
                    # Other errors - don't retry
                    print(f"‚ùå [AIMapperService] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                    return {field: f"[Error: {str(e)[:50]}]" for field in target_fields}
        
        # All retries exhausted
        return {field: "[Error: Max retries exceeded]" for field in target_fields}
    
    async def transform_batch(
        self, 
        rows: List[Dict[str, Any]], 
        target_fields: List[str],
        concurrency: int = 5  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    ) -> List[Dict[str, Any]]:
        """
        ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß (batch processing)
        ‡πÉ‡∏ä‡πâ concurrency ‡∏ï‡πà‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á rate limit
        """
        results = []
        
        # Process in batches to avoid rate limiting
        for i in range(0, len(rows), concurrency):
            batch = rows[i:i + concurrency]
            
            # Create tasks for concurrent execution
            tasks = [
                self.transform_row(row, target_fields)
                for row in batch
            ]
            
            # Execute batch
            batch_results = await asyncio.gather(*tasks)
            
            # Add original data reference
            for j, result in enumerate(batch_results):
                original_row = batch[j]
                # Combine original values for reference
                original_combined = " | ".join(
                    str(v) for v in original_row.values() if v and str(v).strip()
                )
                result["_original_combined"] = original_combined
                result["_original_row"] = original_row
                results.append(result)
            
            print(f"‚úÖ [AIMapperService] ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• batch {i//concurrency + 1}, ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(results)}/{len(rows)}")
            
            # Increased delay between batches to avoid rate limiting
            if i + concurrency < len(rows):
                await asyncio.sleep(1.5)
        
        return results


    async def extract_from_document(
        self, 
        document_text: str, 
        target_fields: List[str]
    ) -> Dict[str, Any]:
        """
        Extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏¢‡∏≤‡∏ß (‡πÄ‡∏ä‡πà‡∏ô PDF)
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö text ‡∏´‡∏•‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤/‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        """
        if not self.model:
            if not self._configure_with_next_key():
                return {field: None for field in target_fields}
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á field descriptions
        field_descriptions = {
            "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà/‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤",
            "category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å, ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡∏ß‡∏±‡∏î",
            "topic": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà, ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
            "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
            "keywords": "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma",
            "detail_overview": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤",
            "detail_location": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà ‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á",
            "detail_hours_contact": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£ Line Facebook",
            "detail_highlights": "‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏•‡∏≤‡∏î",
            "detail_price": "‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏° ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "detail_atmosphere": "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
            "detail_facilities": "‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ WiFi ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥",
            "detail_tips": "‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
        }
        
        fields_list = []
        for field in target_fields:
            desc = field_descriptions.get(field, field)
            fields_list.append(f'  "{field}": "{desc}"')
        fields_json_hint = "{\n" + ",\n".join(fields_list) + "\n}"
        
        # Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö document extraction
        prompt = f"""[CONTEXT]
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Document Extraction Expert ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Structured JSON
‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF ‡πÅ‡∏•‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö fields ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î

[DOCUMENT CONTENT]
---
{document_text[:15000]}
---

[TARGET FIELDS - ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ extract]
{fields_json_hint}

[INSTRUCTIONS]
1. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤
2. Extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏•‡∏á‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ field ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
3. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö summary ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
4. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö detail_* fields ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
5. ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö field ‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤ null
6. **‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö**

[OUTPUT FORMAT]
‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å JSON
"""
        
        for attempt in range(self.MAX_RETRIES):
            try:
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt
                )
                
                response_text = response.text.strip()
                print(f"üîç [AIMapper] ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å AI (500 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å): {response_text[:500]}")
                
                # Clean markdown
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                print(f"üîç [AIMapper] ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß (500 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å): {response_text[:500]}")
                
                extracted = json.loads(response_text)
                
                # Handle nested structure: {"locations": [...]} or list [...]
                if isinstance(extracted, dict) and "locations" in extracted:
                    locations = extracted["locations"]
                    extracted = locations[0] if locations else {}
                    print(f"‚ö†Ô∏è [AIMapper] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏≠‡∏≤‡∏£‡πå‡πÄ‡∏£‡∏¢‡πå 'locations', {len(locations)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                elif isinstance(extracted, list):
                    print(f"‚ö†Ô∏è [AIMapper] AI ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ {len(extracted)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏£‡∏Å")
                    extracted = extracted[0] if extracted else {}
                
                result = {}
                for field in target_fields:
                    result[field] = extracted.get(field) if isinstance(extracted, dict) else None
                
                print(f"‚úÖ [AIMapper] ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len([v for v in result.values() if v])} ‡∏ü‡∏¥‡∏•‡∏î‡πå")
                return result
                
            except json.JSONDecodeError as je:
                print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á JSON: {je}")
                print(f"‚ùå [AIMapper] ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {response_text[:300] if 'response_text' in dir() else 'N/A'}")
                return {field: None for field in target_fields}
                
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "quota" in error_str.lower():
                    print(f"‚ö†Ô∏è [AIMapper] Quota ‡πÄ‡∏ï‡πá‡∏°, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô key...")
                    if self._configure_with_next_key():
                        await asyncio.sleep(min(2 ** attempt, 8))
                        continue
                    else:
                        return {field: None for field in target_fields}
                else:
                    print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                    return {field: None for field in target_fields}
        
        return {field: None for field in target_fields}

    async def extract_with_web_search(
        self, 
        search_query: str, 
        target_fields: List[str]
    ) -> Dict[str, Any]:
        """
        üåê Extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Google Search grounding
        AI ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞ extract ‡∏•‡∏á fields ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
        """
        if not self.model:
            if not self._configure_with_next_key():
                return {field: None for field in target_fields}
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á field descriptions
        field_descriptions = {
            "title": "‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà/‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤",
            "category": "‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å, ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß, ‡∏ß‡∏±‡∏î",
            "topic": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏≤‡πÄ‡∏ü‡πà, ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏ß‡∏±‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
            "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
            "keywords": "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma",
            "detail_overview": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç",
            "detail_location": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà ‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á",
            "detail_hours_contact": "‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£ Line Facebook",
            "detail_highlights": "‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏•‡∏≤‡∏î",
            "detail_price": "‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏° ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢",
            "detail_atmosphere": "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà",
            "detail_facilities": "‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏î‡∏£‡∏ñ WiFi ‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥",
            "detail_tips": "‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
        }
        
        fields_list = []
        for field in target_fields:
            desc = field_descriptions.get(field, field)
            fields_list.append(f'  "{field}": "{desc}"')
        fields_json_hint = "{\n" + ",\n".join(fields_list) + "\n}"
        
        # Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö web search extraction
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢

‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: "{search_query}"

‡πÇ‡∏õ‡∏£‡∏î‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å Google ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏•‡∏á‡πÉ‡∏ô JSON format ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
{fields_json_hint}

‡∏Å‡∏é:
1. ‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö field ‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà null
3. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö summary ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
4. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON object ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô"""

        for attempt in range(self.MAX_RETRIES):
            try:
                # ‡πÉ‡∏ä‡πâ Google Search grounding
                from google.generativeai import types
                
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt,
                    tools=[types.Tool(google_search=types.GoogleSearch())]
                )
                
                response_text = response.text.strip()
                
                # Clean markdown
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                # ‡∏´‡∏≤ JSON object ‡πÉ‡∏ô response
                import re
                json_match = re.search(r'\{[\s\S]*\}', response_text)
                if json_match:
                    response_text = json_match.group()
                
                extracted = json.loads(response_text)
                
                result = {}
                for field in target_fields:
                    result[field] = extracted.get(field)
                
                print(f"‚úÖ [AIMapper] ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: {search_query}")
                return result
                
            except json.JSONDecodeError as je:
                print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á JSON: {je}")
                print(f"Response was: {response_text[:500] if 'response_text' in dir() else 'N/A'}")
                return {field: None for field in target_fields}
                
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "quota" in error_str.lower():
                    print(f"‚ö†Ô∏è [AIMapper] Quota ‡πÄ‡∏ï‡πá‡∏°, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô key...")
                    if self._configure_with_next_key():
                        await asyncio.sleep(min(2 ** attempt, 8))
                        continue
                    else:
                        return {field: None for field in target_fields}
                else:
                    print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö: {e}")
                    return {field: None for field in target_fields}
        
        return {field: None for field in target_fields}

    async def detect_entries(self, document_text: str, target_count: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        üîç Detect entries/topics in a large document
        AI ‡∏à‡∏∞‡∏™‡πÅ‡∏Å‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠/entries ‡∏ó‡∏µ‡πà‡∏û‡∏ö
        
        Args:
            document_text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
            target_count: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (None = AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
            
        Returns:
            List of {title, description} for each detected entry
        """
        if not self.model:
            if not self._configure_with_next_key():
                return []
        
        # Truncate text if too long
        max_chars = 15000
        if len(document_text) > max_chars:
            document_text = document_text[:max_chars] + "\n...[‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô]..."
        
        # Build count instruction
        if target_count and target_count > 0:
            count_instruction = f"4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ {target_count} ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏£‡∏ß‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏¢‡∏Å‡∏¢‡πà‡∏≠‡∏¢‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°)"
        else:
            count_instruction = "4. ‡∏£‡∏∞‡∏ö‡∏∏‡∏ó‡∏∏‡∏Å‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏ö ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô"
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß

‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà/‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏û‡∏ö

[‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£]
{document_text}

[‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á]
1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
2. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏ title ‡πÅ‡∏•‡∏∞ description ‡∏™‡∏±‡πâ‡∏ô‡πÜ
3. ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
{count_instruction}

[‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á output]
[
  {{"title": "‡∏ß‡∏±‡∏î‡∏†‡∏π‡∏°‡∏¥‡∏ô‡∏ó‡∏£‡πå", "description": "‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏à‡∏¥‡∏ï‡∏£‡∏Å‡∏£‡∏£‡∏°‡∏ù‡∏≤‡∏ú‡∏ô‡∏±‡∏á‡∏Å‡∏£‡∏∞‡∏ã‡∏¥‡∏ö‡∏£‡∏±‡∏Å‡∏ö‡∏±‡∏ô‡∏•‡∏∑‡∏≠‡πÇ‡∏•‡∏Å"}},
  {{"title": "‡∏ñ‡∏ô‡∏ô‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô‡∏ô‡πà‡∏≤‡∏ô", "description": "‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡∏±‡∏î‡∏¢‡∏≤‡∏°‡πÄ‡∏¢‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô"}}
]

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:"""

        for attempt in range(self.MAX_RETRIES):
            try:
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt
                )
                
                response_text = response.text.strip()
                
                # Clean markdown
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                entries = json.loads(response_text)
                
                if not isinstance(entries, list):
                    entries = [entries]
                
                print(f"‚úÖ [AIMapper] ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö {len(entries)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
                return entries
                
            except json.JSONDecodeError as je:
                print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á JSON: {je}")
                return []
                
            except Exception as e:
                error_str = str(e)
                if "429" in error_str or "quota" in error_str.lower():
                    print(f"‚ö†Ô∏è [AIMapper] Quota ‡πÄ‡∏ï‡πá‡∏°, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô key...")
                    if self._configure_with_next_key():
                        await asyncio.sleep(min(2 ** attempt, 8))
                        continue
                    else:
                        return []
                else:
                    print(f"‚ùå [AIMapper] ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£: {e}")
                    return []
        
        return []

    async def extract_multiple_entries(
        self,
        document_text: str,
        entries: List[Dict[str, str]],
        target_fields: List[str]
    ) -> List[Dict[str, Any]]:
        """
        üìä Extract data for multiple entries from document
        AI ‡∏à‡∏∞ extract ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ entry ‡∏ï‡∏≤‡∏° fields ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
        """
        if not self.model:
            if not self._configure_with_next_key():
                return []
        
        results = []
        
        for entry in entries:
            entry_title = entry.get("title", "")
            if not entry_title:
                continue
            
            # Create focused search text
            search_prompt = f"‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {entry_title}\n‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: {entry.get('description', '')}"
            combined = f"{search_prompt}\n\n{document_text}"
            
            # Use existing extraction method
            extracted = await self.extract_from_document(
                document_text=combined,
                target_fields=target_fields
            )
            
            # Ensure title is set
            if not extracted.get("title"):
                extracted["title"] = entry_title
            
            results.append(extracted)
        
        print(f"‚úÖ [AIMapper] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {len(results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return results


# Singleton instance
ai_mapper_service = AIMapperService()

